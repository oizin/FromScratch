{"title":"Bitcoin price volatility with ARCH models","markdown":{"yaml":{"title":"Bitcoin price volatility with ARCH models","date":"January 2021","bibliography":"references.bib","format":{"html":{"code-fold":"show"}},"execute":{"freeze":"auto","cache":true}},"headingText":"Introduction","containsRefs":true,"markdown":"\n\n```{r}\n#| echo: false\n#| warning: false\nlibrary(data.table)\nlibrary(ggplot2)\n```\n\nThis post covers some of the basic strategies behind how (financial) time series are analysed and how volatility models work. In particular I examine the ARCH model. Don't take the attempt to forecast the distributions of Bitcoin / US dollar price movements seriously - I would bet precisely \\$0 on this model! I hope to do a more detailed post on how to evaluate distributional forecasts in the future.\n\n\nIt's January 2021 and Bitcoin price have been breaking all time highs. In this context I wanted to explore statistical methods for estimating and forecasting volatility, in particular autoregressive conditional heteroscedasticity (ARCH) models. Volatility is variation around the mean return of a financial asset. Low volatility implies prices are bunched near the mean (or trend) while high volatility implies large swings in prices. It is considered a measure of investment risk. For example, we may be convinced Bitcoin will continue to rise in value over the short term but reluctant to engage in speculation if there is significant volatility reducing our chances of being able to buy in and sell at \"good\" prices (even if there a upward trend). I'll add I'm not an expert on financial markets, and that models and graphs below are coded in R.\n\n```{r}\n#| code-fold: show\n# read in data\n# Source: https://www.kaggle.com/mczielinski/bitcoin-historical-data\ndt_daily_close <- fread(\"./bitcoin-daily-close-2012-2020.csv\")\n```\n\n## Bitcoin bull markets\n\nTo say the Bitcoin (BTC) price has been going up recently was probably an understatement, the price has gone up more 100% since the beginning of 2020! Although if we compare with previous bull market in late 2017 where the price went up more than 1000% it is not a unique occurrence in Bitcoin's history. Indeed, looking at the graph of Bitcoin on a log scale below we see that the recent (relative) growth rate is comparatively low in Bitcoin's history.\n\n```{r, fig.cap=\"Bitcoin daily closing prices (2012 to 2020)\",fig.width=11}\n#| code-fold: true\n# graph bitcoin and log10(bitcoin) over time\np1 <- ggplot(dt_daily_close,aes(x=date,y=Close)) +\n  geom_line() +\n  theme_bw(base_size = 16) +\n  labs(x=\"Year\",y=\"US$\",title=\"BTC price\")\np2 <- ggplot(dt_daily_close,aes(x=date,y=Close)) +\n  geom_line() + \n  scale_y_log10() +\n  theme_bw(base_size = 16) +\n  labs(x=\"Year\",y=\"US$\",\n       title=expression(paste(\"BTC price (\",log[10],\" scale)\"))) +\n  theme(plot.caption = element_text(hjust = 0,size=16))\ngridExtra::grid.arrange(p1,p2)\n```\n\n## Financial time series basics\n\nIt is common in the statistical analysis of financial time series to transform the asset price in order to achieve something closer to a series of independent increments ([a random walk](https://en.wikipedia.org/wiki/Random_walk)). If $B_t$ is the Bitcoin price on day $t$, the daily \"log return\" is $Z_t = log(B_t) - log(B_{t-1})$. Using the log differences might seem rather arbitrary at first but it can justified as 1) making a multiplicative process additive and 2) interpretable as the percentage change in asset value. If $r_t$ is the return at time $t \\in {1,2,...,T}$ for a starting asset value of $W_0$ then $W_T = W_0\\prod_{t=1}^T(1+r_t)$. Taking logarithms gives\n\n\\begin{align}\nlog(W_T) &= log(W_0) + \\sum_{t=1}^T log(1+r_t) \\\\\n &= \\underbrace{log(W_0) + \\sum_{t=1}^{T-1} log(1+r_t)}_{log(W_{T-1})} + log(1+r_T) \\\\\nlog(1+r_T) &= log(W_T) - log(W_{T-1})\\\\\n\\end{align}\n\nFurther for small $r_t$ the percentage price is approximately equal to the log return, i.e. $log \\approx x$. So the [random-walk hypothesis](https://en.wikipedia.org/wiki/Random_walk_hypothesis) hopes that the relative price changes are close to an independent process.\n\n```{r}\n#| code-fold: show\ndt_daily_ret <- dt_daily_close[,.(return = diff(log(Close)))]\ndt_daily_ret[,date := dt_daily_close$date[-1]]\n```\n\nWe can see in the plot below that $Z_t$ appears to be a zero mean process. However, comparing it to a simulated white noise process we see much greater variation in the magnitude of deviations from the the mean. The Bitcoin returns also exhibit clustering in their variance over time. These are characteristics the ARCH model was designed to account for.\n\n```{r,fig.width=11,fig.cap=\"Bitcoin daily returns compared to white noise\"}\n#| code-fold: true\n# compared bitoin log returns to white noise\np1 <- ggplot(dt_daily_ret,aes(x=date,y=return)) +\n  geom_line() +\n  theme_bw(base_size = 16)+\n  coord_cartesian(ylim=c(-0.7,0.7)) +\n  labs(x=\"Year\",y=\"Daily return\",title=\"Bitcoin (US$)\")\nwn <- data.frame(date = dt_daily_ret$date,\n                 wn=rnorm(nrow(dt_daily_ret),\n                 sd=sd(dt_daily_ret$return)))\np2 <- ggplot(wn,aes(x=date,y=wn)) +\n  geom_line()+\n  theme_bw(base_size = 16) +\n  coord_cartesian(ylim=c(-0.7,0.7)) +\n  labs(x=\"Year\",y=\"Daily return\",title=\"White noise\")  +\n  theme(plot.caption = element_text(hjust = 0,size=16))\ngridExtra::grid.arrange(p1,p2)\n```\n\nAn alternative way to look at a times series is plots of the autocorrelation function (ACF) and partial autocorrelation function (PACF). The ACF graphs the correlation between observations at time $Z_t$ and $Z_{t-h}$ for various values of $h$. Since we average over $t$ we are assuming that the series is [stationary](https://en.wikipedia.org/wiki/Stationary_process) - intuitively that it's statistical properties don't depend on $t$. The PACF graphs the correlation between $Z_t$ and $Z_{t-h}$ with all intermediate values $Z_{t-1},Z_{t-2},...,Z_{t-h+1}$ regressed out. Below are ACF and PACF graphs of the series ${Z_t}$ and ${Z_t^2}$. While $Z_t$ appears to have relatively weak patterns the ACF and PACF of the $Z_t^2$ process demonstrates clear dependence in the process variance.\n\n```{r,fig.cap=\"Autocorrelation function of Bitcoin daily returns and squared returns\",fig.width=11,fig.height=8}\n#| code-fold: true\n# Create function to plot acf using ggplot2\nggacf <- function(acf_obj,y,title) {\n  acfrdf <- with(acf_obj, data.frame(lag, acf))\n  if(min(acfrdf$lag) == 1) {\n    acfrdf <- rbind(acfrdf,data.frame(lag=0,acf=1.0))\n  }\n  ggplot(data = acfrdf, mapping = aes(x = lag, y = acf)) +\n       geom_hline(aes(yintercept = 0)) +\n       geom_segment(mapping = aes(xend = lag, yend = 0)) +\n  theme_bw(base_size = 16) +\n  labs(x = \"Lag\",y=y,title = title) +\n  geom_hline(aes(yintercept = 1.96/sqrt(acf_obj$n.used)), \n             linetype = 3, color = 'darkblue')+\n  geom_hline(aes(yintercept = -1.96/sqrt(acf_obj$n.used)), \n             linetype = 3, color = 'darkblue')\n}\n\n# ACF of returns\nacfr <- acf(dt_daily_ret$return, plot = FALSE)\np1 <- ggacf(acfr,\"ACF\",\"Returns\")\n\n# ACF of returns^2\nacfr2 <- acf(dt_daily_ret$return^2,plot = FALSE)\np2 <- ggacf(acfr2,\"ACF\",\"Squared returns\")\n\n# PACF of returns\npacfr <- pacf(dt_daily_ret$return, plot = FALSE)\np3 <- ggacf(pacfr,\"PACF\",\"Returns\")  +\n  theme(plot.caption = element_text(hjust = 0,size=16))\n\n# PACF of returns^2\npacfr2 <- pacf(dt_daily_ret$return^2,plot = FALSE)\np4 <- ggacf(pacfr2,\"PACF\",\"Squared returns\")\n\n\ngridExtra::grid.arrange(p1,p2,p3,p4,ncol=2)\n```\n\nA formal test of independence of a time-series, the Ljung–Box test, strongly rejects independence in $Z_t^2$ with a small p-value. We also reject independence of the $Z_t$ increments but this is much weaker signal.\n\n```{r}\n#| code-fold: show\n# test of Z_t\nBox.test(dt_daily_ret$return,type = \"Ljung-Box\")\n```\n\n```{r}\n#| code-fold: show\n# test of Z_t^2\nBox.test(dt_daily_ret$return^2,type = \"Ljung-Box\")\n```\n\n## Autoregressive conditional heteroscedasticity models\n\nAutoregressive conditional heteroscedasticity (ARCH) models, developed by Robert Engle in 1982, were designed to account for processes in which the variance of the return fluctuates. ARCH processes exhibit the time varying variance and volatility clustering seen in the graph of Bitcoin returns above. An ARCH(p) series is generated as $X_t = \\sqrt h_t e_t$, with $h_t = \\alpha_0 + \\sum \\alpha_i X_{t-i}^2$ and $e_t \\sim N(0,1)$. There have been extensions to the model since 1982 with generalised ARCH (GARCH) and it's various flavours (IGARCH, EGARCH, ...) which allow more complex patterns such as somewhat \"stickier\" volatility clustering.\n\nI always like to try and understand how a model works by either simulating form it (for statistical models) or using simulated data to understand it's performance (for machine learning models). Lets simulate some examples of an ARCH(1) process to get an idea of how the simplest version of the process works.\n\n```{r}\n#| code-fold: show\nsimulate_arch1 <- function(a0,a1,n=1000L) {\n  # function to simulate an ARCH(1) series\n  # a0: ARCH constant\n  # a1: ARCH AR term\n  # n: length of time series\n  xt <- numeric(length = n+1)\n  ee <- rnorm(n+1)  \n  xt[1] <- ee[1]\n  for (i in 2:(n+1)) {\n    ht <- a0 + a1*xt[i-1]^2\n    xt[i] <- ee[i]*sqrt(ht)\n  }\n  xt[2:(n+1)]\n}\n```\n\n```{r, fig.width=11,fig.cap=\"Simulated ARCH(1) processes\"}\n#| code-fold: true\n# simulate an ARCH(1) series\nset.seed(1)\narch1_plts <- vector(mode = \"list\",length = 4)\nfor (i in 1:4) {\n  arch1_sim <- data.frame(t=1:1000, xt=simulate_arch1(1.0,0.6))\n  arch1_plts[[i]] <- ggplot(arch1_sim,aes(x=t,y=xt)) +\n    geom_line() +\n    theme_bw(base_size = 16) +\n    labs(y=expression(x[t]))\n}\ngridExtra::grid.arrange(grobs=arch1_plts)\n```\n\n```{r,fig.cap=\"ACF and PACF for simulated ARCH(1) processes\",fig.width=11,fig.height=8}\n#| code-fold: true\n# ACF of returns\nacfr <- acf(arch1_sim$xt, plot = FALSE)\np1 <- ggacf(acfr,\"ACF\",expression(x[t]))\n\n# ACF of returns^2\nacfr2 <- acf(arch1_sim$xt^2,plot = FALSE)\np2 <- ggacf(acfr2,\"ACF\",expression(paste(x[t],\" squared\")))\n\n# PACF of returns\npacfr <- pacf(arch1_sim$xt, plot = FALSE)\np3 <- ggacf(pacfr,\"PACF\",expression(x[t]))\n\n# PACF of returns^2\npacfr2 <- pacf(arch1_sim$xt^2,plot = FALSE)\np4 <- ggacf(pacfr2,\"PACF\",expression(paste(x[t],\" squared\")))\n\ngridExtra::grid.arrange(p1,p2,p3,p4,ncol=2)\n```\n\nIt is worth remembering that ARCH models are for the volatility, we can also have usual trends, or additional ARIMA components. For example, let's simulate an AR(1) model with ARCH(1) volatility, $X_t = u_0 X_{t-1} + \\sqrt h_t e_t$. The plots of the ACF and PACF for this series shows similar correlation patterns for both ${X_t}$ and ${X_t^2}$.\n\n```{r}\n#| code-fold: show\nsimulate_ar1_arch1 <- function(u0,a0,a1,n=1000L) {\n  # function to simulate AR(1) + ARCH(1) series\n  # u0: autoregressive term\n  # a0: ARCH constant\n  # a1: ARCH AR term\n  # n: length of time series\n  xt <- numeric(length = n+1)\n  ee <- rnorm(n+1)  \n  xt[1] <- ee[1]\n  for (i in 2:(n+1)) {\n    ht <- a0 + a1*xt[i-1]^2\n    xt[i] <- u0*xt[i-1] + ee[i]*sqrt(ht)\n  }\n  xt[2:(n+1)]\n}\n```\n\n```{r, fig.cap=\"Simulated AR(1) + ARCH(1) processes\",fig.width=11}\n#| code-fold: true\n# simulate an AR(1) + ARCH(1) series\nset.seed(1)\nar1arch1_plts <- vector(mode = \"list\",length = 4)\nfor (i in 1:4) {\n  ar1arch1_sim <- data.frame(t=1:1000, xt=simulate_ar1_arch1(0.4,1.0,0.6))\n  ar1arch1_plts[[i]] <- ggplot(ar1arch1_sim,aes(x=t,y=xt)) +\n    geom_line() +\n    theme_bw(base_size = 16) +\n    labs(y=expression(x[t]))\n}\ngridExtra::grid.arrange(grobs=ar1arch1_plts)\n```\n\n```{r,fig.cap=\"ACF and PACF for simulated AR(1) + ARCH(1) processes\",fig.width=11,fig.height=8}\n#| code-fold: true\n# ACF of returns\nacfr <- acf(ar1arch1_sim$xt, plot = FALSE)\np1 <- ggacf(acfr,\"ACF\",expression(x[t]))\n\n# ACF of returns^2\nacfr2 <- acf(ar1arch1_sim$xt^2,plot = FALSE)\np2 <- ggacf(acfr2,\"ACF\",expression(paste(x[t],\" squared\")))\n\n# PACF of returns\npacfr <- pacf(ar1arch1_sim$xt, plot = FALSE)\np3 <- ggacf(pacfr,\"PACF\",expression(x[t]))\n\n# PACF of returns^2\npacfr2 <- pacf(ar1arch1_sim$xt^2,plot = FALSE)\np4 <- ggacf(pacfr2,\"PACF\",expression(paste(x[t],\" squared\")))\n\ngridExtra::grid.arrange(p1,p2,p3,p4,ncol=2)\n```\n\n## Modelling Bitcoin volatility\n\nNow that we've got an idea of how ARCH models work let's move onto modeling Bitcoin returns. We'll use the R package `fGarch` which estimates the model parameters using Quasi-Maximum Likelihood Estimation. I picked an ARCH(2) model based on a quick comparison of model fit statistics for different values of the heteroscedasdicity order. The `garchFit` function prints a lot to the console which you can suppress with `trace = FALSE`.\n\n```{r message=FALSE, warning=FALSE}\n#| code-fold: show\n# fit an ARCH(2) model to Bitcoin returns\nlibrary(fGarch)\nm1 <- garchFit(~arma(0,0)+garch(2,0),dt_daily_ret$return,trace=FALSE)\nsummary(m1)\n```\n\nCalling `summary` on the resulting model object returns estimates of the model parameters and Ljung–Box statistics for the residuals and squared residuals. The model returned is $Z_t = 0.00265 + \\sqrt h_t e_t$ with $h_t = 0.001 + 0.251 Z_{t-1}^2 + 0.254 Z_{t-2}^2$. Notice that the Ljung-Box test is significant for the residuals but not squared residuals. The p in `Q(p)` of the Ljung-Box test results indicates the extent of the autocorrelation lag used in testing for independence of the residuals. So there is evidence of unaccounted for correlation in the data when considering lags up to 15 and 20. However, the ACF and partial ACF suggest that the remaining auto correlation is somewhat complex and weak enough to ignore for the purposes of illustrating basic volatility forecasting with ARCH model.\n\n## Rolling probabilitic forecast\n\nOne use of such a model may be to forecast the one day ahead distribution of returns. Our forecasts are of the form $Z_{t+1} \\sim N(0,\\hat{\\alpha}_0 + \\hat{\\alpha}_1 Z_{t-1}^2 + \\hat{\\alpha}_2 Z_{t-2}^2)$. These forecasted distributions can be used to assess the probability of price movements of a particular size. Since we might believe the parameters of the model are not constant I'll use a rolling forecast window of 300+1 days. So starting at day 301 (2012-10-26) until the final day 3,285 (2020-12-31) I'll fit an ARCH(2) model to the previous 300 days and forecast forward one day. We can see in the results that there is considerable room for improvement, the model fails to capture many of the large price movements, but that it is not producing complete nonsense either.\n\n```{r}\n#| code-fold: true\n# forecast bitoin returns using a rolling ARCH(2) model \ndt_daily_ret$meanForecast <- NA\ndt_daily_ret$meanError <- NA\n\n# this takes a while\nfor (i in 1:(nrow(dt_daily_ret)-300)) {\n  model <- garchFit(~arma(0,0)+garch(2,0),dt_daily_ret$return[i:(300+i)],trace=FALSE)\n  pred <- predict(model, n.ahead = 1)\n  dt_daily_ret$meanError[i+300] <- pred$meanError[1]\n  dt_daily_ret$meanForecast[i+300] <- pred$meanForecast[1] \n}\n\n# some limits\ndt_daily_ret$upperLimit99 <- dt_daily_ret$meanForecast + dt_daily_ret$meanError*qnorm(1-0.01/2)\ndt_daily_ret$lowerLimit99 <- dt_daily_ret$meanForecast - dt_daily_ret$meanError*qnorm(1-0.01/2)\ndt_daily_ret$upperLimit80 <- dt_daily_ret$meanForecast + dt_daily_ret$meanError*qnorm(1-0.2/2)\ndt_daily_ret$lowerLimit80 <- dt_daily_ret$meanForecast - dt_daily_ret$meanError*qnorm(1-0.2/2)\ndt_daily_ret$upperLimit50 <- dt_daily_ret$meanForecast + dt_daily_ret$meanError*qnorm(1-0.5/2)\ndt_daily_ret$lowerLimit50 <- dt_daily_ret$meanForecast - dt_daily_ret$meanError*qnorm(1-0.5/2)\n```\n\n```{r fig.cap=\"The red points are outside the 95% forecast intervals\", fig.height=6,fig.width=11}\n#| code-fold: true\n# graph performance of rolling forecast\ndt_daily_ret$outside <- NA\ndt_daily_ret$outside <- 1*(dt_daily_ret$return > dt_daily_ret$upperLimit99 |\n                             dt_daily_ret$return < dt_daily_ret$lowerLimit99)\n\n\nggplot(dt_daily_ret) +\n  geom_ribbon(aes(ymin=lowerLimit99,ymax=upperLimit99,x=date),fill=\"steelblue2\",alpha=0.5) +\n  geom_ribbon(aes(ymin=lowerLimit80,ymax=upperLimit80,x=date),fill=\"steelblue3\",alpha=0.5) +\n  geom_ribbon(aes(ymin=lowerLimit50,ymax=upperLimit50,x=date),fill=\"steelblue4\",alpha=0.5) +\n    geom_line(aes(x=date,y=return)) +\n  coord_cartesian(xlim=c(as.Date(\"2019-01-01\"),as.Date(\"2020-12-31\")),\n                  ylim=c(-0.5,0.25)) +\n    geom_point(data=dt_daily_ret[dt_daily_ret$outside==TRUE],\n               aes(x=date,y=return),col=\"red\")+\n      geom_point(data=dt_daily_ret[dt_daily_ret$outside==TRUE & \n                                     dt_daily_ret$return > dt_daily_ret$upperLimit99],\n               aes(x=date,y=upperLimit99),col=\"blue\")+\n      geom_point(data=dt_daily_ret[dt_daily_ret$outside==TRUE & \n                                     dt_daily_ret$return < dt_daily_ret$lowerLimit99],\n               aes(x=date,y=lowerLimit99),col=\"blue\")+\n  labs(x=\"Date\",y=\"Bitcoin daily return\") +\n  theme_bw(base_size = 16)\n```\n\n## Assessing the forecasts\n\nA more thorough evaluation of the forecasts involves assessing their calibration and dispersion (I won't go into details on this aspect, see for example Gneiting and Katzfuss (2014)). From the graphs below we see that our forecasts are poorly calibrated - the forecasted probabilities of price movement are not reliable. They are likely to over estimate the probability of a large price movement (overdispersion).\n\n```{r, fig.cap=\"Assessment of calibration\", fig.width=11, fig.height=5}\n#| code-fold: true\n# cumulative probability forecasts\ndt_daily_ret$probForecast <- pnorm(dt_daily_ret$return,mean = dt_daily_ret$meanForecast,sd = dt_daily_ret$meanError)\n\n# PIT\np1 <- ggplot(dt_daily_ret) +\n  geom_histogram(aes(x=probForecast,y=..density..),col=\"white\",fill=\"lightblue\") +\n  theme_bw(base_size=16) +\n  labs(x=\"Forecast probability\")\n\n\n# calibration\ndt_daily_ret$probForecastInt = ceiling(dt_daily_ret$probForecast*20)/20\ncalib_tab <- dt_daily_ret[,.N,by=.(pred=probForecastInt)][order(pred)]\ncalib_tab <- calib_tab[!is.na(pred)]\ncalib_tab[,cumN := cumsum(N)]\ncalib_tab[,obsp := cumN/sum(N)]\ncalib_tab[,obsp_sd := sqrt(obsp*(1-obsp)/N)]\ncalib_tab[,obsp_lower := obsp-2*obsp_sd]\ncalib_tab[,obsp_upper := obsp+2*obsp_sd]\n\n\np2 <- ggplot(calib_tab) +\n  geom_pointrange(aes(x=pred,y=obsp,ymin=obsp_lower,ymax=obsp_upper)) +\n  geom_abline(slope = 1,intercept=0,linetype=2,col=\"blue\")+\n  geom_line(aes(x=pred,y=obsp))+\n  labs(y=\"Observed relative\\nfrequency\",x=\"Forecast probability\")+\n  theme_bw(base_size=16) \n\ngridExtra::grid.arrange(p1,p2,ncol=2)\n```\n\nWe might wonder whether the poor performance came about due to the large drop in March 2020 influencing future predictions. However, this doesn't appear to be the case. The prediction strategy I used is simply not good!\n\n```{r, fig.cap=\"Assessment of calibration (pre March 2020)\", fig.width=11, fig.height=5}\n#| code-fold: true\n# PIT\np1 <- ggplot(dt_daily_ret[date < \"2020-03-01\"]) +\n  geom_histogram(aes(x=probForecast,y=..density..),col=\"white\",fill=\"lightblue\") +\n  theme_bw(base_size=16) +\n  labs(x=\"Forecast probability\")\n\n# calibration\ncalib_tab <- dt_daily_ret[date < \"2020-03-01\",.N,by=.(pred=probForecastInt)][order(pred)]\ncalib_tab <- calib_tab[!is.na(pred)]\ncalib_tab[,cumN := cumsum(N)]\ncalib_tab[,obsp := cumN/sum(N)]\ncalib_tab[,obsp_sd := sqrt(obsp*(1-obsp)/N)]\ncalib_tab[,obsp_lower := obsp-2*obsp_sd]\ncalib_tab[,obsp_upper := obsp+2*obsp_sd]\n\n\np2 <- ggplot(calib_tab) +\n  geom_pointrange(aes(x=pred,y=obsp,ymin=obsp_lower,ymax=obsp_upper)) +\n  geom_abline(slope = 1,intercept=0,linetype=2,col=\"blue\")+\n  geom_line(aes(x=pred,y=obsp))+\n  labs(y=\"Observed relative\\nfrequency\",x=\"Forecast probability\")+\n  theme_bw(base_size=16) \n\ngridExtra::grid.arrange(p1,p2,ncol=2)\n```\n\n## That's all!\n\nThanks for reading. This was a relatively simplistic introduction to the use of ARCH models for forecasting volatility in the Bitcoin market. ARCH models allow the variance of time series at time $t$ to depend on the variance of previous terms ${t-1,t-2,...}$, analogous to how autoregressive models. This allows us to forecast distributions of future prices in a manner that is more reflective of empirical observations of financial time series.\n\n## Reading and links\n\n::: {#refs}\n:::\n","srcMarkdownNoYaml":"\n\n```{r}\n#| echo: false\n#| warning: false\nlibrary(data.table)\nlibrary(ggplot2)\n```\n\nThis post covers some of the basic strategies behind how (financial) time series are analysed and how volatility models work. In particular I examine the ARCH model. Don't take the attempt to forecast the distributions of Bitcoin / US dollar price movements seriously - I would bet precisely \\$0 on this model! I hope to do a more detailed post on how to evaluate distributional forecasts in the future.\n\n## Introduction\n\nIt's January 2021 and Bitcoin price have been breaking all time highs. In this context I wanted to explore statistical methods for estimating and forecasting volatility, in particular autoregressive conditional heteroscedasticity (ARCH) models. Volatility is variation around the mean return of a financial asset. Low volatility implies prices are bunched near the mean (or trend) while high volatility implies large swings in prices. It is considered a measure of investment risk. For example, we may be convinced Bitcoin will continue to rise in value over the short term but reluctant to engage in speculation if there is significant volatility reducing our chances of being able to buy in and sell at \"good\" prices (even if there a upward trend). I'll add I'm not an expert on financial markets, and that models and graphs below are coded in R.\n\n```{r}\n#| code-fold: show\n# read in data\n# Source: https://www.kaggle.com/mczielinski/bitcoin-historical-data\ndt_daily_close <- fread(\"./bitcoin-daily-close-2012-2020.csv\")\n```\n\n## Bitcoin bull markets\n\nTo say the Bitcoin (BTC) price has been going up recently was probably an understatement, the price has gone up more 100% since the beginning of 2020! Although if we compare with previous bull market in late 2017 where the price went up more than 1000% it is not a unique occurrence in Bitcoin's history. Indeed, looking at the graph of Bitcoin on a log scale below we see that the recent (relative) growth rate is comparatively low in Bitcoin's history.\n\n```{r, fig.cap=\"Bitcoin daily closing prices (2012 to 2020)\",fig.width=11}\n#| code-fold: true\n# graph bitcoin and log10(bitcoin) over time\np1 <- ggplot(dt_daily_close,aes(x=date,y=Close)) +\n  geom_line() +\n  theme_bw(base_size = 16) +\n  labs(x=\"Year\",y=\"US$\",title=\"BTC price\")\np2 <- ggplot(dt_daily_close,aes(x=date,y=Close)) +\n  geom_line() + \n  scale_y_log10() +\n  theme_bw(base_size = 16) +\n  labs(x=\"Year\",y=\"US$\",\n       title=expression(paste(\"BTC price (\",log[10],\" scale)\"))) +\n  theme(plot.caption = element_text(hjust = 0,size=16))\ngridExtra::grid.arrange(p1,p2)\n```\n\n## Financial time series basics\n\nIt is common in the statistical analysis of financial time series to transform the asset price in order to achieve something closer to a series of independent increments ([a random walk](https://en.wikipedia.org/wiki/Random_walk)). If $B_t$ is the Bitcoin price on day $t$, the daily \"log return\" is $Z_t = log(B_t) - log(B_{t-1})$. Using the log differences might seem rather arbitrary at first but it can justified as 1) making a multiplicative process additive and 2) interpretable as the percentage change in asset value. If $r_t$ is the return at time $t \\in {1,2,...,T}$ for a starting asset value of $W_0$ then $W_T = W_0\\prod_{t=1}^T(1+r_t)$. Taking logarithms gives\n\n\\begin{align}\nlog(W_T) &= log(W_0) + \\sum_{t=1}^T log(1+r_t) \\\\\n &= \\underbrace{log(W_0) + \\sum_{t=1}^{T-1} log(1+r_t)}_{log(W_{T-1})} + log(1+r_T) \\\\\nlog(1+r_T) &= log(W_T) - log(W_{T-1})\\\\\n\\end{align}\n\nFurther for small $r_t$ the percentage price is approximately equal to the log return, i.e. $log \\approx x$. So the [random-walk hypothesis](https://en.wikipedia.org/wiki/Random_walk_hypothesis) hopes that the relative price changes are close to an independent process.\n\n```{r}\n#| code-fold: show\ndt_daily_ret <- dt_daily_close[,.(return = diff(log(Close)))]\ndt_daily_ret[,date := dt_daily_close$date[-1]]\n```\n\nWe can see in the plot below that $Z_t$ appears to be a zero mean process. However, comparing it to a simulated white noise process we see much greater variation in the magnitude of deviations from the the mean. The Bitcoin returns also exhibit clustering in their variance over time. These are characteristics the ARCH model was designed to account for.\n\n```{r,fig.width=11,fig.cap=\"Bitcoin daily returns compared to white noise\"}\n#| code-fold: true\n# compared bitoin log returns to white noise\np1 <- ggplot(dt_daily_ret,aes(x=date,y=return)) +\n  geom_line() +\n  theme_bw(base_size = 16)+\n  coord_cartesian(ylim=c(-0.7,0.7)) +\n  labs(x=\"Year\",y=\"Daily return\",title=\"Bitcoin (US$)\")\nwn <- data.frame(date = dt_daily_ret$date,\n                 wn=rnorm(nrow(dt_daily_ret),\n                 sd=sd(dt_daily_ret$return)))\np2 <- ggplot(wn,aes(x=date,y=wn)) +\n  geom_line()+\n  theme_bw(base_size = 16) +\n  coord_cartesian(ylim=c(-0.7,0.7)) +\n  labs(x=\"Year\",y=\"Daily return\",title=\"White noise\")  +\n  theme(plot.caption = element_text(hjust = 0,size=16))\ngridExtra::grid.arrange(p1,p2)\n```\n\nAn alternative way to look at a times series is plots of the autocorrelation function (ACF) and partial autocorrelation function (PACF). The ACF graphs the correlation between observations at time $Z_t$ and $Z_{t-h}$ for various values of $h$. Since we average over $t$ we are assuming that the series is [stationary](https://en.wikipedia.org/wiki/Stationary_process) - intuitively that it's statistical properties don't depend on $t$. The PACF graphs the correlation between $Z_t$ and $Z_{t-h}$ with all intermediate values $Z_{t-1},Z_{t-2},...,Z_{t-h+1}$ regressed out. Below are ACF and PACF graphs of the series ${Z_t}$ and ${Z_t^2}$. While $Z_t$ appears to have relatively weak patterns the ACF and PACF of the $Z_t^2$ process demonstrates clear dependence in the process variance.\n\n```{r,fig.cap=\"Autocorrelation function of Bitcoin daily returns and squared returns\",fig.width=11,fig.height=8}\n#| code-fold: true\n# Create function to plot acf using ggplot2\nggacf <- function(acf_obj,y,title) {\n  acfrdf <- with(acf_obj, data.frame(lag, acf))\n  if(min(acfrdf$lag) == 1) {\n    acfrdf <- rbind(acfrdf,data.frame(lag=0,acf=1.0))\n  }\n  ggplot(data = acfrdf, mapping = aes(x = lag, y = acf)) +\n       geom_hline(aes(yintercept = 0)) +\n       geom_segment(mapping = aes(xend = lag, yend = 0)) +\n  theme_bw(base_size = 16) +\n  labs(x = \"Lag\",y=y,title = title) +\n  geom_hline(aes(yintercept = 1.96/sqrt(acf_obj$n.used)), \n             linetype = 3, color = 'darkblue')+\n  geom_hline(aes(yintercept = -1.96/sqrt(acf_obj$n.used)), \n             linetype = 3, color = 'darkblue')\n}\n\n# ACF of returns\nacfr <- acf(dt_daily_ret$return, plot = FALSE)\np1 <- ggacf(acfr,\"ACF\",\"Returns\")\n\n# ACF of returns^2\nacfr2 <- acf(dt_daily_ret$return^2,plot = FALSE)\np2 <- ggacf(acfr2,\"ACF\",\"Squared returns\")\n\n# PACF of returns\npacfr <- pacf(dt_daily_ret$return, plot = FALSE)\np3 <- ggacf(pacfr,\"PACF\",\"Returns\")  +\n  theme(plot.caption = element_text(hjust = 0,size=16))\n\n# PACF of returns^2\npacfr2 <- pacf(dt_daily_ret$return^2,plot = FALSE)\np4 <- ggacf(pacfr2,\"PACF\",\"Squared returns\")\n\n\ngridExtra::grid.arrange(p1,p2,p3,p4,ncol=2)\n```\n\nA formal test of independence of a time-series, the Ljung–Box test, strongly rejects independence in $Z_t^2$ with a small p-value. We also reject independence of the $Z_t$ increments but this is much weaker signal.\n\n```{r}\n#| code-fold: show\n# test of Z_t\nBox.test(dt_daily_ret$return,type = \"Ljung-Box\")\n```\n\n```{r}\n#| code-fold: show\n# test of Z_t^2\nBox.test(dt_daily_ret$return^2,type = \"Ljung-Box\")\n```\n\n## Autoregressive conditional heteroscedasticity models\n\nAutoregressive conditional heteroscedasticity (ARCH) models, developed by Robert Engle in 1982, were designed to account for processes in which the variance of the return fluctuates. ARCH processes exhibit the time varying variance and volatility clustering seen in the graph of Bitcoin returns above. An ARCH(p) series is generated as $X_t = \\sqrt h_t e_t$, with $h_t = \\alpha_0 + \\sum \\alpha_i X_{t-i}^2$ and $e_t \\sim N(0,1)$. There have been extensions to the model since 1982 with generalised ARCH (GARCH) and it's various flavours (IGARCH, EGARCH, ...) which allow more complex patterns such as somewhat \"stickier\" volatility clustering.\n\nI always like to try and understand how a model works by either simulating form it (for statistical models) or using simulated data to understand it's performance (for machine learning models). Lets simulate some examples of an ARCH(1) process to get an idea of how the simplest version of the process works.\n\n```{r}\n#| code-fold: show\nsimulate_arch1 <- function(a0,a1,n=1000L) {\n  # function to simulate an ARCH(1) series\n  # a0: ARCH constant\n  # a1: ARCH AR term\n  # n: length of time series\n  xt <- numeric(length = n+1)\n  ee <- rnorm(n+1)  \n  xt[1] <- ee[1]\n  for (i in 2:(n+1)) {\n    ht <- a0 + a1*xt[i-1]^2\n    xt[i] <- ee[i]*sqrt(ht)\n  }\n  xt[2:(n+1)]\n}\n```\n\n```{r, fig.width=11,fig.cap=\"Simulated ARCH(1) processes\"}\n#| code-fold: true\n# simulate an ARCH(1) series\nset.seed(1)\narch1_plts <- vector(mode = \"list\",length = 4)\nfor (i in 1:4) {\n  arch1_sim <- data.frame(t=1:1000, xt=simulate_arch1(1.0,0.6))\n  arch1_plts[[i]] <- ggplot(arch1_sim,aes(x=t,y=xt)) +\n    geom_line() +\n    theme_bw(base_size = 16) +\n    labs(y=expression(x[t]))\n}\ngridExtra::grid.arrange(grobs=arch1_plts)\n```\n\n```{r,fig.cap=\"ACF and PACF for simulated ARCH(1) processes\",fig.width=11,fig.height=8}\n#| code-fold: true\n# ACF of returns\nacfr <- acf(arch1_sim$xt, plot = FALSE)\np1 <- ggacf(acfr,\"ACF\",expression(x[t]))\n\n# ACF of returns^2\nacfr2 <- acf(arch1_sim$xt^2,plot = FALSE)\np2 <- ggacf(acfr2,\"ACF\",expression(paste(x[t],\" squared\")))\n\n# PACF of returns\npacfr <- pacf(arch1_sim$xt, plot = FALSE)\np3 <- ggacf(pacfr,\"PACF\",expression(x[t]))\n\n# PACF of returns^2\npacfr2 <- pacf(arch1_sim$xt^2,plot = FALSE)\np4 <- ggacf(pacfr2,\"PACF\",expression(paste(x[t],\" squared\")))\n\ngridExtra::grid.arrange(p1,p2,p3,p4,ncol=2)\n```\n\nIt is worth remembering that ARCH models are for the volatility, we can also have usual trends, or additional ARIMA components. For example, let's simulate an AR(1) model with ARCH(1) volatility, $X_t = u_0 X_{t-1} + \\sqrt h_t e_t$. The plots of the ACF and PACF for this series shows similar correlation patterns for both ${X_t}$ and ${X_t^2}$.\n\n```{r}\n#| code-fold: show\nsimulate_ar1_arch1 <- function(u0,a0,a1,n=1000L) {\n  # function to simulate AR(1) + ARCH(1) series\n  # u0: autoregressive term\n  # a0: ARCH constant\n  # a1: ARCH AR term\n  # n: length of time series\n  xt <- numeric(length = n+1)\n  ee <- rnorm(n+1)  \n  xt[1] <- ee[1]\n  for (i in 2:(n+1)) {\n    ht <- a0 + a1*xt[i-1]^2\n    xt[i] <- u0*xt[i-1] + ee[i]*sqrt(ht)\n  }\n  xt[2:(n+1)]\n}\n```\n\n```{r, fig.cap=\"Simulated AR(1) + ARCH(1) processes\",fig.width=11}\n#| code-fold: true\n# simulate an AR(1) + ARCH(1) series\nset.seed(1)\nar1arch1_plts <- vector(mode = \"list\",length = 4)\nfor (i in 1:4) {\n  ar1arch1_sim <- data.frame(t=1:1000, xt=simulate_ar1_arch1(0.4,1.0,0.6))\n  ar1arch1_plts[[i]] <- ggplot(ar1arch1_sim,aes(x=t,y=xt)) +\n    geom_line() +\n    theme_bw(base_size = 16) +\n    labs(y=expression(x[t]))\n}\ngridExtra::grid.arrange(grobs=ar1arch1_plts)\n```\n\n```{r,fig.cap=\"ACF and PACF for simulated AR(1) + ARCH(1) processes\",fig.width=11,fig.height=8}\n#| code-fold: true\n# ACF of returns\nacfr <- acf(ar1arch1_sim$xt, plot = FALSE)\np1 <- ggacf(acfr,\"ACF\",expression(x[t]))\n\n# ACF of returns^2\nacfr2 <- acf(ar1arch1_sim$xt^2,plot = FALSE)\np2 <- ggacf(acfr2,\"ACF\",expression(paste(x[t],\" squared\")))\n\n# PACF of returns\npacfr <- pacf(ar1arch1_sim$xt, plot = FALSE)\np3 <- ggacf(pacfr,\"PACF\",expression(x[t]))\n\n# PACF of returns^2\npacfr2 <- pacf(ar1arch1_sim$xt^2,plot = FALSE)\np4 <- ggacf(pacfr2,\"PACF\",expression(paste(x[t],\" squared\")))\n\ngridExtra::grid.arrange(p1,p2,p3,p4,ncol=2)\n```\n\n## Modelling Bitcoin volatility\n\nNow that we've got an idea of how ARCH models work let's move onto modeling Bitcoin returns. We'll use the R package `fGarch` which estimates the model parameters using Quasi-Maximum Likelihood Estimation. I picked an ARCH(2) model based on a quick comparison of model fit statistics for different values of the heteroscedasdicity order. The `garchFit` function prints a lot to the console which you can suppress with `trace = FALSE`.\n\n```{r message=FALSE, warning=FALSE}\n#| code-fold: show\n# fit an ARCH(2) model to Bitcoin returns\nlibrary(fGarch)\nm1 <- garchFit(~arma(0,0)+garch(2,0),dt_daily_ret$return,trace=FALSE)\nsummary(m1)\n```\n\nCalling `summary` on the resulting model object returns estimates of the model parameters and Ljung–Box statistics for the residuals and squared residuals. The model returned is $Z_t = 0.00265 + \\sqrt h_t e_t$ with $h_t = 0.001 + 0.251 Z_{t-1}^2 + 0.254 Z_{t-2}^2$. Notice that the Ljung-Box test is significant for the residuals but not squared residuals. The p in `Q(p)` of the Ljung-Box test results indicates the extent of the autocorrelation lag used in testing for independence of the residuals. So there is evidence of unaccounted for correlation in the data when considering lags up to 15 and 20. However, the ACF and partial ACF suggest that the remaining auto correlation is somewhat complex and weak enough to ignore for the purposes of illustrating basic volatility forecasting with ARCH model.\n\n## Rolling probabilitic forecast\n\nOne use of such a model may be to forecast the one day ahead distribution of returns. Our forecasts are of the form $Z_{t+1} \\sim N(0,\\hat{\\alpha}_0 + \\hat{\\alpha}_1 Z_{t-1}^2 + \\hat{\\alpha}_2 Z_{t-2}^2)$. These forecasted distributions can be used to assess the probability of price movements of a particular size. Since we might believe the parameters of the model are not constant I'll use a rolling forecast window of 300+1 days. So starting at day 301 (2012-10-26) until the final day 3,285 (2020-12-31) I'll fit an ARCH(2) model to the previous 300 days and forecast forward one day. We can see in the results that there is considerable room for improvement, the model fails to capture many of the large price movements, but that it is not producing complete nonsense either.\n\n```{r}\n#| code-fold: true\n# forecast bitoin returns using a rolling ARCH(2) model \ndt_daily_ret$meanForecast <- NA\ndt_daily_ret$meanError <- NA\n\n# this takes a while\nfor (i in 1:(nrow(dt_daily_ret)-300)) {\n  model <- garchFit(~arma(0,0)+garch(2,0),dt_daily_ret$return[i:(300+i)],trace=FALSE)\n  pred <- predict(model, n.ahead = 1)\n  dt_daily_ret$meanError[i+300] <- pred$meanError[1]\n  dt_daily_ret$meanForecast[i+300] <- pred$meanForecast[1] \n}\n\n# some limits\ndt_daily_ret$upperLimit99 <- dt_daily_ret$meanForecast + dt_daily_ret$meanError*qnorm(1-0.01/2)\ndt_daily_ret$lowerLimit99 <- dt_daily_ret$meanForecast - dt_daily_ret$meanError*qnorm(1-0.01/2)\ndt_daily_ret$upperLimit80 <- dt_daily_ret$meanForecast + dt_daily_ret$meanError*qnorm(1-0.2/2)\ndt_daily_ret$lowerLimit80 <- dt_daily_ret$meanForecast - dt_daily_ret$meanError*qnorm(1-0.2/2)\ndt_daily_ret$upperLimit50 <- dt_daily_ret$meanForecast + dt_daily_ret$meanError*qnorm(1-0.5/2)\ndt_daily_ret$lowerLimit50 <- dt_daily_ret$meanForecast - dt_daily_ret$meanError*qnorm(1-0.5/2)\n```\n\n```{r fig.cap=\"The red points are outside the 95% forecast intervals\", fig.height=6,fig.width=11}\n#| code-fold: true\n# graph performance of rolling forecast\ndt_daily_ret$outside <- NA\ndt_daily_ret$outside <- 1*(dt_daily_ret$return > dt_daily_ret$upperLimit99 |\n                             dt_daily_ret$return < dt_daily_ret$lowerLimit99)\n\n\nggplot(dt_daily_ret) +\n  geom_ribbon(aes(ymin=lowerLimit99,ymax=upperLimit99,x=date),fill=\"steelblue2\",alpha=0.5) +\n  geom_ribbon(aes(ymin=lowerLimit80,ymax=upperLimit80,x=date),fill=\"steelblue3\",alpha=0.5) +\n  geom_ribbon(aes(ymin=lowerLimit50,ymax=upperLimit50,x=date),fill=\"steelblue4\",alpha=0.5) +\n    geom_line(aes(x=date,y=return)) +\n  coord_cartesian(xlim=c(as.Date(\"2019-01-01\"),as.Date(\"2020-12-31\")),\n                  ylim=c(-0.5,0.25)) +\n    geom_point(data=dt_daily_ret[dt_daily_ret$outside==TRUE],\n               aes(x=date,y=return),col=\"red\")+\n      geom_point(data=dt_daily_ret[dt_daily_ret$outside==TRUE & \n                                     dt_daily_ret$return > dt_daily_ret$upperLimit99],\n               aes(x=date,y=upperLimit99),col=\"blue\")+\n      geom_point(data=dt_daily_ret[dt_daily_ret$outside==TRUE & \n                                     dt_daily_ret$return < dt_daily_ret$lowerLimit99],\n               aes(x=date,y=lowerLimit99),col=\"blue\")+\n  labs(x=\"Date\",y=\"Bitcoin daily return\") +\n  theme_bw(base_size = 16)\n```\n\n## Assessing the forecasts\n\nA more thorough evaluation of the forecasts involves assessing their calibration and dispersion (I won't go into details on this aspect, see for example Gneiting and Katzfuss (2014)). From the graphs below we see that our forecasts are poorly calibrated - the forecasted probabilities of price movement are not reliable. They are likely to over estimate the probability of a large price movement (overdispersion).\n\n```{r, fig.cap=\"Assessment of calibration\", fig.width=11, fig.height=5}\n#| code-fold: true\n# cumulative probability forecasts\ndt_daily_ret$probForecast <- pnorm(dt_daily_ret$return,mean = dt_daily_ret$meanForecast,sd = dt_daily_ret$meanError)\n\n# PIT\np1 <- ggplot(dt_daily_ret) +\n  geom_histogram(aes(x=probForecast,y=..density..),col=\"white\",fill=\"lightblue\") +\n  theme_bw(base_size=16) +\n  labs(x=\"Forecast probability\")\n\n\n# calibration\ndt_daily_ret$probForecastInt = ceiling(dt_daily_ret$probForecast*20)/20\ncalib_tab <- dt_daily_ret[,.N,by=.(pred=probForecastInt)][order(pred)]\ncalib_tab <- calib_tab[!is.na(pred)]\ncalib_tab[,cumN := cumsum(N)]\ncalib_tab[,obsp := cumN/sum(N)]\ncalib_tab[,obsp_sd := sqrt(obsp*(1-obsp)/N)]\ncalib_tab[,obsp_lower := obsp-2*obsp_sd]\ncalib_tab[,obsp_upper := obsp+2*obsp_sd]\n\n\np2 <- ggplot(calib_tab) +\n  geom_pointrange(aes(x=pred,y=obsp,ymin=obsp_lower,ymax=obsp_upper)) +\n  geom_abline(slope = 1,intercept=0,linetype=2,col=\"blue\")+\n  geom_line(aes(x=pred,y=obsp))+\n  labs(y=\"Observed relative\\nfrequency\",x=\"Forecast probability\")+\n  theme_bw(base_size=16) \n\ngridExtra::grid.arrange(p1,p2,ncol=2)\n```\n\nWe might wonder whether the poor performance came about due to the large drop in March 2020 influencing future predictions. However, this doesn't appear to be the case. The prediction strategy I used is simply not good!\n\n```{r, fig.cap=\"Assessment of calibration (pre March 2020)\", fig.width=11, fig.height=5}\n#| code-fold: true\n# PIT\np1 <- ggplot(dt_daily_ret[date < \"2020-03-01\"]) +\n  geom_histogram(aes(x=probForecast,y=..density..),col=\"white\",fill=\"lightblue\") +\n  theme_bw(base_size=16) +\n  labs(x=\"Forecast probability\")\n\n# calibration\ncalib_tab <- dt_daily_ret[date < \"2020-03-01\",.N,by=.(pred=probForecastInt)][order(pred)]\ncalib_tab <- calib_tab[!is.na(pred)]\ncalib_tab[,cumN := cumsum(N)]\ncalib_tab[,obsp := cumN/sum(N)]\ncalib_tab[,obsp_sd := sqrt(obsp*(1-obsp)/N)]\ncalib_tab[,obsp_lower := obsp-2*obsp_sd]\ncalib_tab[,obsp_upper := obsp+2*obsp_sd]\n\n\np2 <- ggplot(calib_tab) +\n  geom_pointrange(aes(x=pred,y=obsp,ymin=obsp_lower,ymax=obsp_upper)) +\n  geom_abline(slope = 1,intercept=0,linetype=2,col=\"blue\")+\n  geom_line(aes(x=pred,y=obsp))+\n  labs(y=\"Observed relative\\nfrequency\",x=\"Forecast probability\")+\n  theme_bw(base_size=16) \n\ngridExtra::grid.arrange(p1,p2,ncol=2)\n```\n\n## That's all!\n\nThanks for reading. This was a relatively simplistic introduction to the use of ARCH models for forecasting volatility in the Bitcoin market. ARCH models allow the variance of time series at time $t$ to depend on the variance of previous terms ${t-1,t-2,...}$, analogous to how autoregressive models. This allows us to forecast distributions of future prices in a manner that is more reflective of empirical observations of financial time series.\n\n## Reading and links\n\n::: {#refs}\n:::\n"},"formats":{"html":{"identifier":{"display-name":"HTML","target-format":"html","base-format":"html"},"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":true,"freeze":"auto","echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"ipynb-shell-interactivity":null,"plotly-connected":true,"engine":"knitr"},"render":{"keep-tex":false,"keep-typ":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"show","code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-min-runs":1,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[],"notebook-links":true},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","css":["../../styles.css"],"output-file":"index.html"},"language":{"toc-title-document":"Table of contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","other-links-title":"Other Links","code-links-title":"Code Links","launch-dev-container-title":"Launch Dev Container","launch-binder-title":"Launch Binder","article-notebook-label":"Article Notebook","notebook-preview-download":"Download Notebook","notebook-preview-download-src":"Download Source","notebook-preview-back":"Back to Article","manuscript-meca-bundle":"MECA Bundle","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","appendix-view-license":"View License","title-block-author-single":"Author","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Published","title-block-modified":"Modified","title-block-keywords":"Keywords","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","tools-share":"Share","tools-download":"Download","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-text-placeholder":"","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search-label":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-wordcount":"Word Count","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items","listing-page-words":"{0} words","listing-page-filter":"Filter","draft":"Draft"},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.6.42","editor":"visual","theme":"cosmo","date-format":"MMMM, YYYY","title-block-banner":true,"title":"Bitcoin price volatility with ARCH models","date":"January 2021","bibliography":["references.bib"]},"extensions":{"book":{"multiFile":true}}}},"projectFormats":["html"]}